---
title: "Rapport EI Exposome"
author: "Groupe 5"
date: "`r Sys.Date()`"
output: pdf_document
classoption: a4paper
---


# Introduction

La phrase du philosophe José Ortega y Gasset : « Je suis moi et mes circonstances », n'est pas loin de ce que la science a prouvé par la suite : nous sommes le résultat de notre génome et de nos interactions avec notre environnement. C'est pourquoi le développement de l'être humain pendant l'enfance peut être fortement altéré par de nombreux facteurs, depuis l'alimentation, le tabagisme et la pollution pendant la période de grosses jusqu'à l'activité physique de l'enfant.

Le projet HELIX, Human Early-life Exposome, vise à prendre en compte le maximum de ces facteurs, appelés exposomes, qui peuvent conditionner la croissance des enfants. En particulier, l'objet d'étude de cet article est le développement neurologique des enfants jusqu'à l'âge de 11 ans. 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Load data
load("data/exposome.RData")
# Load necessary libraries
library(tidyverse)
library(ggplot2)
library(ggrepel)
library(ggfortify)
library(dplyr)
library(pheatmap)
library(factoextra)
library(FactoMineR)
library(readxl)
library(reshape2)
library(RColorBrewer)
library(glmnet)
```

# Description des données

The projet Athlete nous a fourni avec les données de 1301 personnes collectés dans 6 pays différentes: France, Espagne, Grèce, Royaume-Uni, Norvège et Lituanie.

Les donnés ont été collectées de trois manières différentes, par questionnaires, pour recolecter les habitudes de vie et facteurs socio-écologiques;  capteurs personnels, pour recolecter composition de l'air, et modélisation des exposomes externes en utilisant Système d’information géographique (SIG) et Géolocalisation des domiciles des participants pendant la grossesse et l’enfance et des écoles des enfants.


# Détection des covariantes principales influant le modèle
Dans un premier pas, on s'est concentré sur les valeurs numériques de l'exposome.

Ceci a été fait pour pouvoir effectuer une analyse de composantes principales sur les données obtenues et identifier les "covariates" influant sur les différentes expositions afin de déterminer lesquelles sont à prendre en compte les analyses suivantes.

```{r covariants, echo=FALSE, out.width="30%"}
# Split data so we only have numerical columns
exposome_num <- exposome %>% select_if(is.numeric)
exposome_factors <- exposome %>% select_if(is.factor)

# Do a PCA
pca <- prcomp(exposome_num, scale = TRUE)

plotting_data <- cbind(as.data.frame(pca$x), covariates)

# Get list of column names in covariates
covariate_names <- colnames(covariates)

# Do this for every covariate
for (covariate in covariate_names) {
  # Show scatter plot on principal plane
  print(autoplot(pca, data = plotting_data, colour = covariate))
  #readline(prompt = "Press [Enter] to see the next plot...")
}

# Show that the cohorts are not created at the same time because
# year of birth is linked to cohort
pheatmap(table(covariates$h_cohort, covariates$e3_yearbir_None),
         cluster_rows = FALSE,
         cluster_cols = FALSE,
         color = colorRampPalette(c("white", "orange"))(50),
         main = "Cohorts and year of birth")

```

L'analyse en composantes principales nous permet d'identifier une forte corrélation avec la variable h_cohort, qui représente le pays dans lequel les données ont été collectées et à e3_yearbir_None qui représente l’année de naissance des enfants. Dans la suite du projet, nous ne prendrons en compte que la variable h_cohort. En effet, il semblerait que les cohortes ne soient pas créées en même temps car l'année de naissance est visiblement liée à la cohorte (chaque cohorte correspond à certaines années de naissance).

Les familles d’exposition qui vont être considérés sont : Organochlorines, Air pollution, Phthalates, Lifestyle and PFAS.

# Analyse des Exposomes de type Facteur

On prend maintenant les exposomes qualitatifs pour analyser leur impact sur le phénotype choisi, hs_Gen-Tot. Pour ce faire, nous transformons les facteurs en données numériques pour les traiter en obtenant leur p-value dans le modèle linéaire généralisé. On ajuste les p-values calculés et on les représentent sur une heatmap. Puis, pour pouvoir identifier si elles sont pertinentes ou non pour notre phénotype, on utilise le logarithme des valeurs. On constate qu'il n'y a pas de facteurs significatifs dans le comportement neuronal. C'est pour cette raison que le reste de l'analyse ne portera que sur les données numériques.

```{r, echo=FALSE}
#Trier les facteurs
exp_fact= exposome %>%
  select(where(~is.factor(.)))

#tranformation des facteurs en données numeriques pour les traiter
exp_fact_transf= matrix(data= NA, nrow = nrow(exp_fact), ncol = ncol(exp_fact))

i=1
for (factos in colnames(exp_fact)){
  exp_fact_transf[,i]= as.numeric(exp_fact[[factos]])
  i=i+1
}
colnames(exp_fact_transf) <- colnames(exp_fact)

# Assuming exp_fact_transf, covariates, and phenotype are already defined
df1 = data.frame(exp_fact_transf, 
                 cohort = covariates$h_cohort,
                 phenotype[, -1])

fit_fact = prcomp(exp_fact_transf, scale = TRUE)

# Initialize the p-values matrix
pvalues_mat <- matrix(NA, nrow = dim(exp_fact_transf)[2], ncol = ncol(phenotype[, 2:6]))

i = 1
for (pheno in colnames(phenotype[, 2:6])) {
  j = 1
  if (all(phenotype[, pheno] %in% 0:1)) {
    for (expo in colnames(exp_fact_transf)) {
      glm_model = glm(phenotype[, pheno] ~ cohort + exp_fact_transf[, expo], data = df1)
      pvalues_mat[j, i] <- tail(summary(glm_model)$coefficient, n = 1)[4]
      j = j + 1
    }
  } else {
    for (expo in colnames(exp_fact_transf)) {
      glm_model = glm(phenotype[, pheno] ~ cohort + exp_fact_transf[, expo], family = gaussian, data = df1)
      pvalues_mat[j, i] <- tail(summary(glm_model)$coefficient, n = 1)[4]
      j = j + 1
    }
  }
  i = i + 1
}

pvalues_fact <- as.data.frame(pvalues_mat)

# Set column and row names for pvalues_fact
colnames(pvalues_fact) <- colnames(phenotype[, 2:6])
rownames(pvalues_fact) <- colnames(exp_fact_transf)

# Adjust pvalues
pvalues_fact_adj <- as.data.frame(p.adjust(pvalues_fact[, "hs_Gen_Tot"], "fdr"))

# Prepare annotation data frame
mat_row = data.frame(family = codebook$family[1:222][which(codebook$variable_name[1:222] %in% rownames(pvalues_fact))])
rownames(mat_row) <- rownames(pvalues_fact)

# Prepare colors for the annotation
unique_families <- unique(mat_row$family)
mat_colors <- list(family = colorRampPalette(brewer.pal(8, "Set2"))(length(unique_families)))
names(mat_colors$family) <- unique_families

# Create the heatmap
pheatmap(
  mat = pvalues_fact,
  color = colorRampPalette(c("#000091", "white", "#E1000F"))(50),
  annotation_row = mat_row,
  annotation_colors = mat_colors,
  cluster_rows = FALSE,
  cluster_cols = FALSE,
  fontsize = 10,
  main = "Exposomes' correlation to phenotypes"
)

neg_log_p_values = -log10(pvalues_fact_adj)
threshold <- -log10(0.05)
annotations <- as.data.frame(ifelse(neg_log_p_values >= threshold, "Significant", "Non-Significant"))
rownames(annotations) <- rownames(neg_log_p_values)
colnames(annotations) <- colnames(neg_log_p_values)

significant_values_fac = cbind(pvalues_fact, pvalues_fact_adj, codebook$family[1:222][which(codebook$variable_name %in% rownames(pvalues_fact))])[annotations$hs_Gen_Tot == "Significant", ]

```
Nous nous intéressons ensuite aux exposomes numériques afin de déterminer lesquels sont corrélés avec l'exposome que nous avons choisi, et ont ainsi une influence non négligeable. Nous utilisons à nouveau un modèle de régression linéaire généralisé pour cela et nous étudions les p-values, que nous aurons ajustées au préalable à l'aide de la méthode "False Discovery Rate" (FDR).

# Matrice de “corrélations” (p_values) entre les expositions numériques et les différents phénotypes
```{r p_values, echo=FALSE}

df = data.frame(exposome_num[, -1], 
                cohort = covariates$h_cohort,
                phenotype[, -1])

fit_num = prcomp(exposome_num[, -1], scale = TRUE)

pvalues_mat <- matrix( , nrow=dim(exposome_num[, -1])[2], ncol=1)

j = 1
for (expo in colnames(exposome_num[, -1])) {
  glm = glm(phenotype[, "hs_Gen_Tot"] ~ cohort + exposome_num[, expo], family = gaussian, data = df)
  pvalues_mat[j, 1] <- tail(summary(glm)$coefficient, n=1)[4]
  j = j + 1
}

colnames(pvalues_mat) <- c("hs_Gen_Tot")
rownames(pvalues_mat) <- colnames(exposome_num[, -1])

pvalues_mat_ajuste <- as.data.frame(p.adjust(pvalues_mat, "fdr"))
colnames(pvalues_mat_ajuste) <- c("hs_Gen_Tot")
rownames(pvalues_mat_ajuste) <- colnames(exposome_num[, -1])

mat_row = data.frame(family = codebook$family[1:222][which(codebook$variable_name[1:222] %in% rownames(pvalues_mat))])
rownames(mat_row) <- rownames(pvalues_mat)

mat_colors <- list(family = colorRampPalette(brewer.pal(8, "Set2"))(length(unique(codebook$family[1:222]))))
names(mat_colors$family) <- unique(codebook$family[1:222])

pheatmap(
  mat = pvalues_mat,
  color = colorRampPalette(c("#000091", "white", "#E1000F"))(50),
  annotation_row = mat_row,
  annotation_colors = mat_colors,
  cluster_rows = FALSE,
  cluster_cols = FALSE,
  fontsize          = 4,
  main              = "Exposomes' correlation to phenotypes",
  legend = FALSE
)

neg_log_p_values = -log10(pvalues_mat_ajuste)
threshold <- -log10(0.05)
annotations <- as.data.frame(ifelse(neg_log_p_values >= threshold, "Significant", "Non-Significant"))
rownames(annotations) <- rownames(neg_log_p_values)
colnames(annotations) <- colnames(neg_log_p_values)

pheatmap(
  mat = neg_log_p_values,
  cluster_rows = FALSE,
  cluster_cols = FALSE,
  annotation_row = annotations,
  fontsize          = 5,
  main              = "Exposomes' correlation to phenotypes (log scale)"
)

significant_values_num = cbind(pvalues_mat, pvalues_mat_ajuste, codebook$family[1:222][which(codebook$variable_name %in% rownames(pvalues_mat))])[annotations$hs_Gen_Tot == "Significant", ]
rownames(significant_values_num) <- rownames(annotations)[which(annotations$hs_Gen_Tot == "Significant")]
colnames(significant_values_num) <- c("pvalue", "Adjusted pvalue", "Family")
print(significant_values_num)
```
Nous modifions les p_values pour les avoir en échelle logarithmique afin de pouvoir identifier visuellement quels exposomes sont significatifs, avant d'extraire la matrice des exposomes significatifs ainsi que leur p-value.

# Analyse univarié: Effet des expositions sur le phénotype d'intérêt

Nous nous concentrons maintenant sur l'effet de la famille "Organochlorines" sur le phénotype choisi. 

```{r p_values_mat, echo=FALSE}

# Extraire la famille organochlorines 
organochlorine_df=exposome_num[,as.character(codebook$variable_name[2:166][which(codebook$family=="Organochlorines")])]

#Initialisation du vecteur 
p_values_mat=matrix(,nrow=dim(organochlorine_df)[2],ncol=1)
colnames(p_values_mat) <- c("Phénotype")
rownames(p_values_mat) <- colnames(organochlorine_df)

#Générer toutes  les p_values de cette famille pour le vecteur 
j=1
for (expo in colnames(organochlorine_df)){
  glm = glm(phenotype[,"hs_Gen_Tot"]~ covariates$h_cohort+exposome_num[,expo], family=gaussian, data=df)
  p_values_mat[j,1] = summary(glm)$coefficients[2,"Pr(>|t|)"]
  j = j + 1
}

#Barplot pour identification des p values les plus significatives ( les plus petites ) -> Grande présence des pcb 
phenotypes <- as.double(p_values_mat)

# Transform the vector in data frame
df2 <- data.frame(Phénotype = rownames(p_values_mat), Valeur = phenotypes)
df2 <- df2[order(df2$Valeur, decreasing = TRUE), ]
#Barplot
ggplot(df2, aes(x = reorder(Phénotype, Valeur), y = Valeur)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Valeurs des phénotypes", x = "Phénotype", y = "Valeur") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
#Relation entre le taux de pcb présents dans la cohorte et l'indice Gen_Tot en comparant les deux graphes 
#Boxplot pour le taux de pcb consommé par la mère selon le pays 
ggplot(df, aes(x=covariates$h_cohort, y=hs_pcb170_madj_Log2, fill=cohort))+geom_boxplot()+labs(title="Influence de la cohorte sur le taux de pcb émis ", 
                                                                                      x="Cohorte",
                                                                                      y="hs_pcb170_madj_Log2")+ theme_minimal()+theme(legend.position = "none")                                                                                                             #Boxplot pour l'indice comportemental selon le pays                                                                           
ggplot(df, aes(x=covariates$h_cohort, y=hs_Gen_Tot, fill=cohort))+geom_boxplot()+labs(title="Influence de la cohorte sur le développement neuronal", 
            x="Cohorte",
            y="hs_Gen_Tot")+ theme_minimal()+theme(legend.position = "none") 
``` 

Pour mieux étudier les influences des uniques expositions dans la famille organochlorines sur le phénotype de développement neuronal, on a identifié les exposomes les plus significatifs selon leur p-value dans cette famille à partir d’une régression linéaire généralisée. L’influence significative du taux de polychlorinated biphenyl  PCB (138 et 170 ) a été remarqué, ceux-ci étant des composés chimiques utilisés dans diverses applications industrielles et commerciales et dont les études ont montré la nocivité sur la santé de l’être humain. On se pose alors la question de l’influence de la cohorte sur le taux du pcb consommé par la mère et l’enfant, vu qu’il y a des pays plus industriels que d’autres.

Effectivement le taux de gen_tot le plus bas (développment neuronal retardé) a été mesuré dans les pays avec le taux de pcb le plus élevé. Ceci a été mesuré dans le cas où ca soit la mère qui a consommé ces produits, mais leur consommation par l'enfant ne semble pas avoir d'influence significative. 


# Prédiction: Methode LASSO

L'objectif à présent est de proposer un modèle multi-expositions afin de tenter de mettre en évidence un lien entre les exposomes et le développement neuronal de l'enfant, tout en prenant en compte les "covariates" dont on a identifié l'effet précédemment.

```{r, echo=FALSE}
chosen_pheno = "hs_Gen_Tot"

encodage_cohort <- matrix(0, nrow=dim(exposome)[1], ncol=length(unique(covariates$h_cohort)))
for (i in 1:nrow(encodage_cohort)) {
  encodage_cohort[i, covariates$h_cohort[i]] <- 1
}

x <- as.matrix(cbind(exposome_num[, rownames(significant_values_num)], encodage_cohort))
y <- phenotype[, chosen_pheno]
penalty = rep(1, dim(x)[2] - 4)
for (i in 1:4) {
  penalty[dim(x)[2] - 4 + i] = 0
}

cv.lasso <- cv.glmnet(x, y, family="gaussian", alpha=1, penalty.factor = penalty)

optimal_lambda <- cv.lasso$lambda.min
cat("Optimal lambda:", optimal_lambda, "\n")

# Extract coefficients at the optimal lambda
lasso_coefficients <- coef(cv.lasso, s = "lambda.min")

# Predict using the lasso model
predictions <- predict(cv.lasso, s = "lambda.min", newx = x)

cat("Corrélation : ", cor(y, predictions), "\n")

# # Plot Predicted vs. Actual values
plot(y, predictions, xlab = "Actual Values", ylab = "Predicted Values",
     main = "Actual vs. Predicted Values")
abline(0, 1, col = "red")  # Add a diagonal line for reference
```
Le modèle proposé ici n'est pas très satisfaisant, ne proposant qu'une corrélation d'environ 46%. Le graphe suivant illustre l'aspect insatisfaisant du modèle, car les valeurs prédites peuvent être très différentes des valeurs réelles.

# Conclusion
